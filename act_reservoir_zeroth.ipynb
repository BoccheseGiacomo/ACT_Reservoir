{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.optimize import basinhopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACT_reservoir:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, max_iter=20):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        self.total_dim = 1 + input_dim + hidden_dim + output_dim + 1  # Including bias and halting node\n",
    "        self.W = np.random.uniform(-2, 2, (self.total_dim, self.total_dim))\n",
    "\n",
    "        # Index ranges for different parts of the state vector\n",
    "        self.input_indices = range(1, input_dim + 1)\n",
    "        self.hidden_indices = range(input_dim + 1, input_dim + hidden_dim + 1)\n",
    "        self.output_indices = range(input_dim + hidden_dim + 1, input_dim + hidden_dim + output_dim + 1)\n",
    "        self.halting_index = input_dim + hidden_dim + output_dim + 1\n",
    "\n",
    "    def relu(self,x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def predict(self, xi):\n",
    "        # Create initial state vector with given input, xi, and set bias unit to 1\n",
    "        self.x = np.zeros((self.total_dim, 1))\n",
    "        self.x[0] = 1  # Bias unit\n",
    "        self.x[self.input_indices] = xi.reshape((self.input_dim, 1))  # Input part\n",
    "\n",
    "        t = 0\n",
    "        while t < self.max_iter and self.x[self.halting_index][0] <= 1:\n",
    "            self.x = self.relu(self.W @ self.x)\n",
    "            t += 1\n",
    "\n",
    "        # Extracting and returning the output part of the state vector\n",
    "        return self.x[self.output_indices],t\n",
    "\n",
    "    def summary(self):\n",
    "        print(\"Total Parameters:\", self.total_dim ** 2)  # Since W is a square matrix\n",
    "        print(\"Input Dimension:\", self.input_dim)\n",
    "        print(\"Hidden Dimension:\", self.hidden_dim)\n",
    "        print(\"Output Dimension:\", self.output_dim)\n",
    "        print(\"Max Iterations:\", self.max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "model = ACT_reservoir(2, 10, 1) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with a sample input\n",
    "xi = np.array([0.5, 0.7])\n",
    "output,steps = model.predict(xi)\n",
    "print(\"Output:\", output)\n",
    "print(\"Steps:\",steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "num_samples = 1000\n",
    "\n",
    "# Generate random pairs of integers between 0 and 100\n",
    "factors = np.random.randint(0, 101, size=(num_samples, 2))\n",
    "\n",
    "# Compute the product of each pair\n",
    "products = np.prod(factors, axis=1).reshape(-1, 1, 1)\n",
    "\n",
    "# Combine factors and products into a single dataset\n",
    "# Each element in the dataset will be ([factor1, factor2], [[product]])\n",
    "dataset = [(factors[i].reshape(-1, 1), products[i]) for i in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(weights, model, train_data, batch_size=5):\n",
    "    # Reshape the weights and set them in the model\n",
    "    model.W = weights.reshape(model.W.shape)\n",
    "\n",
    "    # Randomly sample a batch from the training data\n",
    "    batch_indices = np.random.choice(len(train_data), batch_size, replace=False)\n",
    "    batch = [train_data[i] for i in batch_indices]\n",
    "\n",
    "    total_loss = 0\n",
    "    for xi, yi in batch:\n",
    "        predicted_output, _ = model.predict(xi)\n",
    "        # Assuming a simple mean squared error for the loss\n",
    "        total_loss += np.mean((predicted_output.flatten() - yi) ** 2)\n",
    "\n",
    "    return total_loss / len(batch) * 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ACT_reservoir(2, 7, 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounds for the weights in the optimization\n",
    "bounds = [(-4, 4)] * (model.total_dim ** 2)\n",
    "\n",
    "# Use Differential Evolution with the new fitness function\n",
    "result = differential_evolution(fitness, bounds, args=(model, dataset, 100), maxiter=100, disp=True,popsize=100,strategy=\"randtobest1bin\")\n",
    "\n",
    "# Set the optimized weights in the model\n",
    "optimized_weights = result.x\n",
    "model.W = optimized_weights.reshape(model.W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model\n",
    "model = ACT_reservoir(input_dim=2, hidden_dim=10, output_dim=1, max_iter=20)\n",
    "\n",
    "# Flatten the initial weights of the model\n",
    "initial_weights = model.W.flatten()\n",
    "\n",
    "# Bounds for the weights in the optimization\n",
    "bounds = [(-2, 2)] * len(initial_weights)\n",
    "\n",
    "# Define a minimizer_kwargs dictionary for basinhopping\n",
    "minimizer_kwargs = {\"method\": \"L-BFGS-B\", \"bounds\": bounds, \"args\": (model, dataset)}\n",
    "\n",
    "# Use Simulated Annealing to optimize the weights\n",
    "result = basinhopping(fitness, initial_weights, minimizer_kwargs=minimizer_kwargs, niter=100, disp=True)\n",
    "\n",
    "# Set the optimized weights in the model\n",
    "optimized_weights = result.x\n",
    "model.W = optimized_weights.reshape(model.W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING/EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with a sample input\n",
    "xi = np.array([1,1])\n",
    "output,steps = model.predict(xi)\n",
    "print(\"Output:\", output)\n",
    "print(\"Steps:\",steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
